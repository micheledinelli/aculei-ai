\documentclass[12pt,a4paper,twoside]{article}

%------------------------------ encoding
\usepackage[utf8]{inputenc}

%------------------------------ page layout
\usepackage[left=3cm,right=3cm,top=4cm,bottom=5cm]{geometry}

%------------------------------ clickable toc and links styles
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%------------------------------ font preferences (1) or sc
%\usepackage[sc]{mathpazo} 
%usepackage{newpxmath}

%------------------------------ font preferences (2) 
%\usepackage[libertine,cmintegrals,cmbraces,vvarbb]{newtxmath}

%------------------------------ font preferences (3) 
%\usepackage[libertine,cmintegrals,cmbraces,vvarbb]{newtxmath}

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{\fill}

    \vspace*{0.5cm}
    
    \huge ACULEI
    
    \vspace*{1cm}
    \small Brajucha Filippo, Dinelli Michele, Hanna Yossef
    
    \vspace*{0.5cm}
    \small Dicembre 2023
    
    \vspace*{\fill}
\end{titlepage}

%\maketitle

\newpage

\section*{Abstract}

Questo report tratta della realizzazione di un'intelligenza artificiale al servizio di un archivio fotografico 
online. Il progetto si chiama ACULEI e nasce dall'idea di Tobia Faverio, un fotografo nato a Milano e cresciuto 
in Umbria. ACULEI è una raccolta molta vasta di fotografie scattate da foto-trappole sparse per un boschetto nel 
cuore dell'Umbria. Le foto-trappole sono state disposte da Tobia durante i primi mesi della Pandemia da virus 
SARS-CoV-2 per monitorare quale specie animali frequentassero quelle zone. 

Sono stati prodotti numerosi scatti (ad oggi più di 17 000) che ritraggono vari animali come istrici, cinghiali, 
caprioli e addirittura lupi. ACULEI dunque vuole offrire un'esperienza virtuale e interattiva per esplorare 
l'archivio fotografico nato dalla raccolta di scatti. 

Per rendere migliore l'esperienza è stata sviluppata un'intelligenza artificiale che possa guidare il visitatore 
dell'archivio, offrendogli un percorso selezionato così da scoprire le fotografie simili o correlate.
 
\newpage

\tableofcontents

\newpage

\section{Raccolta dati}
Capire come condividere tutti i dati, quale piattaforma non comprime le fotografie e permette di caricarne /
scaricare così tante? WeTransfer, Mega, Dropbox? alla fine è stato scelto Dropbox con un account premium, i 
40GB di foto sono stati suddivisi in 10 cartelle in modo da permettere il download (Dropbox ha un limite di 
dimensione che può comprimere al fine di saricare).

\section{Creazione Dataset}
Dalle immagini vogliamo ottenere un data-set contentente le informazioni che più ci interessano, in modo da 
poterle clusterizzare a seconda delle caratteristiche.\\
Il data-set viene creato a partire dai meta-dati dell'immagine e viene arricchito con degli altri valori
calcolati a partire dagli stessi.\\
I dati che abbiamo voluto raccogliere per ogni immagine sono:
\begin{itemize}
    \item NUM Camera
    \item Timestamp (Data e Ora)
    \item Fase Lunare
    \item Hash (univoco)
    \item Nome Immagine (più per una questione di debugging)
    \item Temperatura
\end{itemize}

\section{Dataset}
L'obiettivo di questa sezione è l'estrazione di dati ordinati e corretti, partendo dall'insieme grezzo 
di immagini 
raccolte a partire dal 2020 per trasformarle in dati manipolabili e significativi.

\subsection{Raccolta dati}
Il primo problema riscontrato è strettamente correlato alla raccolta dei dati
che sono stati forniti in maniera non ordinata e non strutturata. La prima operazione effettuata è 
stata quella di scaricare le immagini da Dropbox, dopopodiché sono stati presi in considerazioni più 
approcci per poter estrarre i dati dai file immagine.
\subsubsection{Prima fase}
Il primo approccio adottato è stato quello di utilizzare sistemi di riconoscimento ottico dei caratteri 
\textit{(OCR)} per estrarre i dati dai file immagine. In particolare è stato sviluppato uno script in 
Python che utilizza integrando diverse librerie come \textit{easyocr, pytesseract, keras-ocr} per 
estrarre i dati dai file immagine. Questo tentativo ha permesso di estrarre i dati dai file immagine, ma 
ha presentato diversi problemi tra cui la scarsa qualità dei dati per alcuni campi e sopratutto i tempi 
di esecuzione molto lunghi. 
\subsubsection{Seconda fase}
In questa seconda fase è stata mantenuta l'idea di utilizzare gli \textit{OCR}, ma quelli integrati nei 
dispositivi \textit{MacOS} e \textit{Ios}. Nello specifico è stata implementata una \textit{shortcut} che 
permette di estrarre i dati dai file immagine e di salvarli in un file \textit{.csv}. Questa soluzione è 
stata effettivimante più efficace nel riconoscimento dei caratteri, ma presentava tempi di esecuzioni molto 
lunghi e la necessità di utilizzare dispositivi \textit{MacOS} o \textit{Ios}.

\subsubsection{Terza fase}
La terza fase è stata quella di utilizzare un sistema di lettura dei meta-dati dei file immagine. In 
particolare è stato utilizzato \textit{exiftool}, un software open source che permette leggere e 
manipolare meta-dati di immagini immagine. Questa soluzione ha permesso di estrarre i dati in maniera molto 
più veloce e una qualità dei dati molto più alta. Inoltre è possibile questa soluzione su qualsiasi sistema 
operativo aumentandone la versatilità.
\subsubsection{Quarta fase}
La terza fase è stata molto precisa, l'unico problema riscontrato è stata la mancanza dei dati relativi 
alla temperatura nei meta-dati. Questo problema è stato risolto utilizzando un sistema di 
\textit{OCR, pytesseract} per estrarre i dati, solamente relativi alla temperatura, dalle foto e inserirli 
nel file \textit{.csv}. In questo modo il \textit{dataset} era quasi completato.
\subsubsection{Quinta fase}
In questa ultima fase il \textit{dataset} presentava delle mancanze per quanto riguarda la temperatura. Per 
risolvere questo problema è stata effettuata una seconda iterazione con gli \textit{OCR} utilizzando la 
libreria di \textit{easyocr}. Quest'ultima ha restituito un risultato più accurato e efficace rispetto a 
\textit{pytesseract} ed è stato possibile terminare la popolazione del \textit{dataset}.

\subsection{Meta-Dati}
Questa fase è stata molto lunga poichè i dati da raccogliere sono molti e le tecniche con cui può essere fatto 
(bene o male, lenamente o velocemente) sono altrettante.\\
Siamo partiti da una raccolta di 300 foto (0.5\%) in modo da impiegare meno tempo per verificare la correttezza 
dei dati.

\subsubsection{Estrazione Meta-Dati}
Molti dati erano presenti all'interno della foto (proprio nella parte grafica), altri erano facilmente ricavabili 
dalle caratteristiche dalle proprietà del file, altri ancora erano più complessi e nascosti, oppure addirittura 
da calcolare partendo da dati più semplici.\\
Abbiamo testato diverse tecniche per la raccolta dati (in ordine cronologico di testing):
\begin{enumerate}
    \item OCR - Abbiamo testato alcuni OCR tra i più diffusi in mercato (ex. EasyOCR, PyTesseract), sono stati 
          riscontrati dei problemi dovuti ai tempi di esecuzione e alla precisione
    \item Apple Lens - Abbiamo utilizzato la shortcut per MacBook AIR M1 ma anche questa volta i tempi di 
          esecuzione erano molto lunghi
    \item Lettura Filesystem - Abbiamo utilizzato inizialmente ExifTool ma non riuscivamo ad ottenere tutti i 
          dati di cui avevamo bisogno
\end{enumerate}
Vedendo che la lettura del FileSystem sembrava quella più efficiente abbiamo provato ad approfondire la tecnica.
\\\\
\textbf{Problema}: Non tutti i dati che vorremmo ottenere\\
\\
\textbf{Soluzione}: Utilizzare il wrapper Python \textit{PyExifTool}\\
\textbf{Esito}: Abbiamo trovato molti più meta-dati dalla stessa immagine\\
\\

\paragraph{Analisi situazione}
\begin{itemize}
    \item Per sviluppare tutto con OCR ci vuole troppo tempo (esecuzione lenta)
    \item Utilizzare la shortcut di Apple è ancora più laborioso
    \item La scelta migliore è l'analisi del filesystem con PyExifTool
\end{itemize}
Quindi abbiamo proseguito con la creazione del data-set con tutte le fotografie a disposizione (40GB)

\paragraph{Problemi}
\textbf{Problema 1}: Tempistiche troppo elevate per 16.000 foto\\
\textbf{Soluzione 1}: Dopo aver analizzato il costo di ogni sub-operazione abbiamo escluso il calcolo 
dell'hash e deciso di calcolarlo in seguito perchè rallenta molto il processo. Purtroppo questo non ci 
permette di escludere a priori i doppioni.\\
\\
\textbf{Problema 2}: Alcuni meta-dati sono incompleti\\
\textbf{Soluzione 2}: Abbiamo analizzato se fosse un problema randomico oppure un problema sistematico, 
quindi abbiamo deciso di optare per una soluzione ibrida OCR + FileSystem Analysis.\\
\\
\textbf{Problema 3}: Non c'è la temperatura nei meta-dati\\
\textbf{Soluzione 3}: Utilizzare OCR specializzato solo su quello, quindi effettuare una lettura della 
barra in basso (croppare immagine di 11/12 in altezza).\\
\\

\paragraph{Conclusione}
Obiettivo : Per ogni immagine ottenere: NUM Camera, Timestamp (Data e Ora), Fase Lunare, Hash, Nome
Immagine, Temperatura\\
Quindi : mancano Hash e Fase Lunare

\subsubsection{Manipolazione Meta-Dati}
I dati mancanti sono \textit{Hash} e \textit{Fase Lunare}, entrambi dati ricavabili da calcoli effettuati
su quelli esistenti.\\

\paragraph{Fase Lunare}
Il calcolo della fase lunare è stato complesso, abbiamo risocontrato alcuni problemi.\\
Inizialmente abbiamo utilizzato la libreria \textbf{Python Ephem} (pypi.org/project/ephem) che però è 
risultata troppo sofisticatata e quindi inutilmente complessa, facendoci individuare delle distribuzioni 
anomale dei dati. La soluzione è stata quella di sostituirla con uno script trovato online, 
\textbf{moonphase.py} (moon\_phase.py), molto più accurato e utile al nostro scopo.

\subsubsection{Inferenza}
Una volta raccolti tutti i dati abbiamo deciso di effettuare un'analisi un po più approfondita dei dati 
che avevamo a disposizione, in modo da individuare pattern ricorrenti e, magari, anche degli eventi 
particolari messi in risalto dai dati stessi.\\
Le rappreesentazioni grafiche che ci sembravano più utili e propedeutiche sono state: 
\begin{itemize}
    \item \textbf{num Foto / Mese} - con eliminazione di outilier per rendere il grafico più significativo
    \item \textbf{num Foto / Camera} - considerando che alcune cam sono attive da più o meno tempo
    \item \textbf{num Foto / Fase Lunare} e \textbf{(num Foto / Camera) / Fase Lunare}
\end{itemize} 
Tutti i grafici realizzati sono recuperabili nel file \textit{data\_visual.ipynb}

\section{Clustering}

\section{Conclusioni}


\end{document}