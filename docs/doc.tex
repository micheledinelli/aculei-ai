\title{AI-2023}\documentclass[12pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[left=3cm,right=3cm,top=4cm,bottom=5cm]{geometry}

%------------------------------ font preferences (1) or sc
\usepackage[sc]{mathpazo} 
\usepackage{newpxmath}

%------------------------------ font preferences (2) 
%\usepackage[libertine,cmintegrals,cmbraces,vvarbb]{newtxmath}

\author{Brajucha Filippo, Dinelli Michele, Hanna Youssef}
\title{Report AI}

\begin{document}

\maketitle

\section*{Abstract}
Aculei è un progetto nato per rendere disponibile un archivio fotografico contenente foto di animali 
scattate da fototrappole automatiche collocate nella campagna Umbra. Da un'idea di Tobia Faverio 
(il fotografo proprietario dell'archivio fotografico) nasce il progetto Aculei che ha come obiettivo 
rendere fruibile l'archivio online fornendo un'esperienza interattiva agli utenti guidata
dall'intelligenza artificiale. Aculei vuole infatti rafforzare il legame tra natura e tecnologia 
che in questo contesto nasce dal momento stesso nel quale viene scattata una fotografia. Le foto trappole 
oggetti tencologi e automatici che si legano al contesto naturale circostante immortalando la natura 
nel suo stato puro. La volontà è proporre questo concetto fornendo un percorso virtuale tra le 
fotografie scattate, guidato dall'intelligenza artificiale, la quale subentra come portavoce di tecnologia, 
affiancandosi alla natura.       
\newpage

\tableofcontents

\newpage

\section{Raccolta Dati}
Capire come condividere tutti i dati, quale piattaforma non comprime le fotografie e permette di caricarne /
scaricare così tante? WeTransfer, Mega, Dropbox? alla fine è stato scelto Dropbox con un account premium, i 
40GB di foto sono stati suddivisi in 10 cartelle in modo da permettere il download (Dropbox ha un limite di 
dimensione che può comprimere al fine di saricare).

\section{Creazione Dataset}
Dalle immagini vogliamo ottenere un data-set contentente le informazioni che più ci interessano, in modo da 
poterle clusterizzare a seconda delle caratteristiche.\\
Il data-set viene creato a partire dai meta-dati dell'immagine e viene arricchito con degli altri valori
calcolati a partire dagli stessi.\\
I dati che abbiamo voluto raccogliere per ogni immagine sono:
\begin{itemize}
    \item NUM Camera
    \item Timestamp (Data e Ora)
    \item Fase Lunare
    \item Hash (univoco)
    \item Nome Immagine (più per una questione di debugging)
    \item Temperatura
\end{itemize}

\subsection{Meta-Dati}
Questa fase è stata molto lunga poichè i dati da raccogliere sono molti e le tecniche con cui può essere fatto 
(bene o male, lenamente o velocemente) sono altrettante.\\
Siamo partiti da una raccolta di 300 foto (0.5\%) in modo da impiegare meno tempo per verificare la correttezza 
dei dati.

\subsubsection{Estrazione Meta-Dati}
Molti dati erano presenti all'interno della foto (proprio nella parte grafica), altri erano facilmente ricavabili 
dalle caratteristiche dalle proprietà del file, altri ancora erano più complessi e nascosti, oppure addirittura 
da calcolare partendo da dati più semplici.\\
Abbiamo testato diverse tecniche per la raccolta dati (in ordine cronologico di testing):
\begin{enumerate}
    \item OCR - Abbiamo testato alcuni OCR tra i più diffusi in mercato (ex. EasyOCR, PyTesseract), sono stati 
          riscontrati dei problemi dovuti ai tempi di esecuzione e alla precisione
    \item Apple Lens - Abbiamo utilizzato la shortcut per MacBook AIR M1 ma anche questa volta i tempi di 
          esecuzione erano molto lunghi
    \item Lettura Filesystem - Abbiamo utilizzato inizialmente ExifTool ma non riuscivamo ad ottenere tutti i 
          dati di cui avevamo bisogno
\end{enumerate}
Vedendo che la lettura del FileSystem sembrava quella più efficiente abbiamo provato ad approfondire la tecnica.
\\\\
\textbf{Problema}: Non tutti i dati che vorremmo ottenere\\
\\
\textbf{Soluzione}: Utilizzare il wrapper Python \textit{PyExifTool}\\
\textbf{Esito}: Abbiamo trovato molti più meta-dati dalla stessa immagine\\
\\

\paragraph{Analisi situazione}
\begin{itemize}
    \item Per sviluppare tutto con OCR ci vuole troppo tempo (esecuzione lenta)
    \item Utilizzare la shortcut di Apple è ancora più laborioso
    \item La scelta migliore è l'analisi del filesystem con PyExifTool
\end{itemize}
Quindi abbiamo proseguito con la creazione del data-set con tutte le fotografie a disposizione (40GB)

\paragraph{Problemi}
\textbf{Problema 1}: Tempistiche troppo elevate per 16.000 foto\\
\textbf{Soluzione 1}: Dopo aver analizzato il costo di ogni sub-operazione abbiamo escluso il calcolo 
dell'hash e deciso di calcolarlo in seguito perchè rallenta molto il processo. Purtroppo questo non ci 
permette di escludere a priori i doppioni.\\
\\
\textbf{Problema 2}: Alcuni meta-dati sono incompleti\\
\textbf{Soluzione 2}: Abbiamo analizzato se fosse un problema randomico oppure un problema sistematico, 
quindi abbiamo deciso di optare per una soluzione ibrida OCR + FileSystem Analysis.\\
\\
\textbf{Problema 3}: Non c'è la temperatura nei meta-dati\\
\textbf{Soluzione 3}: Utilizzare OCR specializzato solo su quello, quindi effettuare una lettura della 
barra in basso (croppare immagine di 11/12 in altezza).\\
\\

\paragraph{Conclusione}
Obiettivo : Per ogni immagine ottenere: NUM Camera, Timestamp (Data e Ora), Fase Lunare, Hash, Nome
Immagine, Temperatura\\
Quindi : mancano Hash e Fase Lunare

\subsubsection{Manipolazione Meta-Dati}



\end{document}