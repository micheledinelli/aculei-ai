\title{AI-2023}\documentclass[12pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[left=3cm,right=3cm,top=4cm,bottom=5cm]{geometry}

%------------------------------ font preferences (1) or sc
\usepackage[sc]{mathpazo} 
\usepackage{newpxmath}

%------------------------------ font preferences (2) 
%\usepackage[libertine,cmintegrals,cmbraces,vvarbb]{newtxmath}

\author{Brajucha Filippo, Dinelli Michele, Hanna Youssef}
\title{Report AI}

\begin{document}

\maketitle

\section*{Abstract}
Aculei è un progetto nato per rendere disponibile un archivio fotografico contenente foto di animali 
scattate da fototrappole automatiche collocate nella campagna Umbra. Da un'idea di Tobia Faverio 
(il fotografo proprietario dell'archivio fotografico) nasce il progetto Aculei che ha come obiettivo 
rendere fruibile l'archivio online fornendo un'esperienza interattiva agli utenti guidata
dall'intelligenza artificiale. Aculei vuole infatti rafforzare il legame tra natura e tecnologia 
che in questo contesto nasce dal momento stesso nel quale viene scattata una fotografia. Le foto trappole 
oggetti tencologi e automatici che si legano al contesto naturale circostante immortalando la natura 
nel suo stato puro. La volontà è proporre questo concetto fornendo un percorso virtuale tra le 
fotografie scattate, guidato dall'intelligenza artificiale, la quale subentra come portavoce di tecnologia, 
affiancandosi alla natura.       
\newpage

\tableofcontents

\newpage

\section{Raccolta Dati}
Capire come condividere tutti i dati, quale piattaforma non comprime le fotografie e permette di caricarne /
scaricare così tante? WeTransfer, Mega, Dropbox? alla fine è stato scelto Dropbox con un account premium, i 
40GB di foto sono stati suddivisi in 10 cartelle in modo da permettere il download (Dropbox ha un limite di 
dimensione che può comprimere al fine di saricare).

\section{Creazione Dataset}
Dalle immagini vogliamo ottenere un data-set contentente le informazioni che più ci interessano, in modo da 
poterle clusterizzare a seconda delle caratteristiche.\\
Il data-set viene creato a partire dai meta-dati dell'immagine e viene arricchito con degli altri valori
calcolati a partire dagli stessi.\\
I dati che abbiamo voluto raccogliere per ogni immagine sono:
\begin{itemize}
    \item NUM Camera
    \item Timestamp (Data e Ora)
    \item Fase Lunare
    \item Hash (univoco)
    \item Nome Immagine (più per una questione di debugging)
    \item Temperatura
\end{itemize}

\section{Dataset}
L'obiettivo di questa sezione è l'estrazione di dati ordinati e corretti, partendo dall'insieme grezzo di immagini 
raccolte a partire dal 2020 per trasformarle in dati manipolabili e significativi.

\subsection{Raccolta dati}
Il primo problema riscontrato è strettamente correlato alla raccolta dei dati
che sono stati forniti in maniera non ordinata e non strutturata. La prima operazione effettuata è stata quella di scaricare le immagini da Dropbox, dopopodiché sono stati presi in considerazioni più approcci per poter estrarre i dati dai file immagine.
\subsubsection{Prima fase}
Il primo approccio adottato è stato quello di utilizzare sistemi di riconoscimento ottico dei caratteri \textit{(OCR)} per estrarre i dati dai file immagine. In particolare è stato sviluppato uno script in Python che utilizza integrando diverse librerie come \textit{easyocr, pytesseract, keras-ocr} per estrarre i dati dai file immagine. Questo tentativo ha permesso di estrarre i dati dai file immagine, ma ha presentato diversi problemi tra cui la scarsa qualità dei dati per alcuni campi e sopratutto i tempi di esecuzione molto lunghi. 
\subsubsection{Seconda fase}
In questa seconda fase è stata mantenuta l'idea di utilizzare gli \textit{OCR}, ma quelli integrati nei dispositivi \textit{MacOS} e \textit{Ios}. Nello specifico è stata implementata una \textit{shortcut} che permette di estrarre i dati dai file immagine e di salvarli in un file \textit{.csv}. Questa soluzione è stata effettivimante più efficace nel riconoscimento dei caratteri, ma presentava tempi di esecuzioni molto lunghi e la necessità di utilizzare dispositivi \textit{MacOS} o \textit{Ios}.

\subsubsection{Terza fase}
La terza fase è stata quella di utilizzare un sistema di lettura dei meta-dati dei file immagine. In particolare è stato utilizzato \textit{exiftool}, un software open source che permette leggere e manipolare meta-dati di immagini immagine. Questa soluzione ha permesso di estrarre i dati in maniera molto più veloce e una qualità dei dati molto più alta. Inoltre è possibile questa soluzione su qualsiasi sistema operativo aumentandone la versatilità.
\subsubsection{Quarta fase}
La terza fase è stata molto precisa, l'unico problema riscontrato è stata la mancanza dei dati relativi alla temperatura nei meta-dati. Questo problema è stato risolto utilizzando un sistema di \textit{OCR, pytesseract} per estrarre i dati, solamente relativi alla temperatura, dalle foto e inserirli nel file \textit{.csv}. In questo modo il \textit{dataset} era quasi completato.
\subsubsection{Quinta fase}
In questa ultima fase il \textit{dataset} presentava delle mancanze per quanto riguarda la temperatura. Per risolvere questo problema è stata effettuata una seconda iterazione con gli \textit{OCR} utilizzando la libreria di \textit{easyocr}. Quest'ultima ha restituito un risultato più accurato e efficace rispetto a \textit{pytesseract} ed è stato possibile terminare la popolazione del \textit{dataset}.
\section{Clustering}

\section{Conclusioni}

\subsection{Meta-Dati}
Questa fase è stata molto lunga poichè i dati da raccogliere sono molti e le tecniche con cui può essere fatto 
(bene o male, lenamente o velocemente) sono altrettante.\\
Siamo partiti da una raccolta di 300 foto (0.5\%) in modo da impiegare meno tempo per verificare la correttezza 
dei dati.

\subsubsection{Estrazione Meta-Dati}
Molti dati erano presenti all'interno della foto (proprio nella parte grafica), altri erano facilmente ricavabili 
dalle caratteristiche dalle proprietà del file, altri ancora erano più complessi e nascosti, oppure addirittura 
da calcolare partendo da dati più semplici.\\
Abbiamo testato diverse tecniche per la raccolta dati (in ordine cronologico di testing):
\begin{enumerate}
    \item OCR - Abbiamo testato alcuni OCR tra i più diffusi in mercato (ex. EasyOCR, PyTesseract), sono stati 
          riscontrati dei problemi dovuti ai tempi di esecuzione e alla precisione
    \item Apple Lens - Abbiamo utilizzato la shortcut per MacBook AIR M1 ma anche questa volta i tempi di 
          esecuzione erano molto lunghi
    \item Lettura Filesystem - Abbiamo utilizzato inizialmente ExifTool ma non riuscivamo ad ottenere tutti i 
          dati di cui avevamo bisogno
\end{enumerate}
Vedendo che la lettura del FileSystem sembrava quella più efficiente abbiamo provato ad approfondire la tecnica.
\\\\
\textbf{Problema}: Non tutti i dati che vorremmo ottenere\\
\\
\textbf{Soluzione}: Utilizzare il wrapper Python \textit{PyExifTool}\\
\textbf{Esito}: Abbiamo trovato molti più meta-dati dalla stessa immagine\\
\\

\paragraph{Analisi situazione}
\begin{itemize}
    \item Per sviluppare tutto con OCR ci vuole troppo tempo (esecuzione lenta)
    \item Utilizzare la shortcut di Apple è ancora più laborioso
    \item La scelta migliore è l'analisi del filesystem con PyExifTool
\end{itemize}
Quindi abbiamo proseguito con la creazione del data-set con tutte le fotografie a disposizione (40GB)

\paragraph{Problemi}
\textbf{Problema 1}: Tempistiche troppo elevate per 16.000 foto\\
\textbf{Soluzione 1}: Dopo aver analizzato il costo di ogni sub-operazione abbiamo escluso il calcolo 
dell'hash e deciso di calcolarlo in seguito perchè rallenta molto il processo. Purtroppo questo non ci 
permette di escludere a priori i doppioni.\\
\\
\textbf{Problema 2}: Alcuni meta-dati sono incompleti\\
\textbf{Soluzione 2}: Abbiamo analizzato se fosse un problema randomico oppure un problema sistematico, 
quindi abbiamo deciso di optare per una soluzione ibrida OCR + FileSystem Analysis.\\
\\
\textbf{Problema 3}: Non c'è la temperatura nei meta-dati\\
\textbf{Soluzione 3}: Utilizzare OCR specializzato solo su quello, quindi effettuare una lettura della 
barra in basso (croppare immagine di 11/12 in altezza).\\
\\

\paragraph{Conclusione}
Obiettivo : Per ogni immagine ottenere: NUM Camera, Timestamp (Data e Ora), Fase Lunare, Hash, Nome
Immagine, Temperatura\\
Quindi : mancano Hash e Fase Lunare

\subsubsection{Manipolazione Meta-Dati}



\end{document}